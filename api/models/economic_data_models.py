"""
Database models for economic data storage and management
"""

from sqlalchemy import Column, Integer, String, Float, DateTime, Text, Boolean, ForeignKey, JSON, Index
from sqlalchemy.orm import relationship
from sqlalchemy.sql import func
from datetime import datetime
from typing import Optional, Dict, Any
import uuid

from database import Base


class EconomicIndicator(Base):
    """Economic indicators metadata and configuration"""
    __tablename__ = "economic_indicators"
    
    id = Column(Integer, primary_key=True, index=True)
    code = Column(String(50), unique=True, index=True, nullable=False)
    name = Column(String(200), nullable=False)
    description = Column(Text)
    unit = Column(String(50))
    frequency = Column(String(20))  # daily, weekly, monthly, quarterly, annual
    source = Column(String(100), default="Bank of Canada")
    category = Column(String(100))  # inflation, employment, gdp, etc.
    is_active = Column(Boolean, default=True)
    
    # Configuration
    data_source_url = Column(String(500))
    update_frequency_hours = Column(Integer, default=24)
    lag_days = Column(Integer, default=0)  # How many days behind real-time
    
    # Metadata
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    updated_at = Column(DateTime(timezone=True), onupdate=func.now())
    
    # Relationships
    data_points = relationship("EconomicDataPoint", back_populates="indicator")
    forecasts = relationship("EconomicForecast", back_populates="indicator")
    
    def __repr__(self):
        return f"<EconomicIndicator(code='{self.code}', name='{self.name}')>"


class EconomicDataPoint(Base):
    """Individual economic data points with time series data"""
    __tablename__ = "economic_data_points"
    
    id = Column(Integer, primary_key=True, index=True)
    indicator_id = Column(Integer, ForeignKey("economic_indicators.id"), nullable=False)
    
    # Data
    date = Column(DateTime(timezone=True), nullable=False, index=True)
    value = Column(Float, nullable=False)
    raw_value = Column(Float)  # Original value before processing
    
    # Quality and metadata
    quality_score = Column(Float, default=1.0)  # 0.0 to 1.0
    is_preliminary = Column(Boolean, default=False)
    is_revised = Column(Boolean, default=False)
    revision_note = Column(Text)
    
    # Source tracking
    source_batch_id = Column(String(100))
    ingestion_timestamp = Column(DateTime(timezone=True), server_default=func.now())
    
    # Additional metadata
    data_metadata = Column(JSON)  # Flexible metadata storage
    
    # Relationships
    indicator = relationship("EconomicIndicator", back_populates="data_points")
    
    # Indexes for performance
    __table_args__ = (
        Index('idx_indicator_date', 'indicator_id', 'date'),
        Index('idx_date_desc', 'date', postgresql_using='btree'),
    )
    
    def __repr__(self):
        return f"<EconomicDataPoint(indicator_id={self.indicator_id}, date='{self.date}', value={self.value})>"


class EconomicForecast(Base):
    """Economic forecasts generated by ML models"""
    __tablename__ = "economic_forecasts"
    
    id = Column(Integer, primary_key=True, index=True)
    indicator_id = Column(Integer, ForeignKey("economic_indicators.id"), nullable=False)
    model_run_id = Column(String(100), index=True)  # MLflow run ID
    
    # Forecast data
    forecast_date = Column(DateTime(timezone=True), nullable=False)  # When forecast was made
    target_date = Column(DateTime(timezone=True), nullable=False, index=True)  # What date is being forecast
    predicted_value = Column(Float, nullable=False)
    
    # Confidence intervals
    confidence_level = Column(Float, default=0.95)  # 95% confidence
    lower_bound = Column(Float)
    upper_bound = Column(Float)
    
    # Model information
    model_name = Column(String(100))
    model_version = Column(String(50))
    
    # Forecast horizon and type
    horizon_days = Column(Integer)  # How many days into the future
    forecast_type = Column(String(50))  # point, interval, distribution
    
    # Quality metrics
    uncertainty_score = Column(Float)
    drift_score = Column(Float)
    
    # Metadata
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    
    # Relationships
    indicator = relationship("EconomicIndicator", back_populates="forecasts")
    
    # Indexes
    __table_args__ = (
        Index('idx_forecast_target', 'indicator_id', 'target_date'),
        Index('idx_model_run', 'model_run_id'),
    )
    
    def __repr__(self):
        return f"<EconomicForecast(indicator_id={self.indicator_id}, target_date='{self.target_date}', value={self.predicted_value})>"


class DataQualityCheck(Base):
    """Data quality monitoring and validation results"""
    __tablename__ = "data_quality_checks"
    
    id = Column(Integer, primary_key=True, index=True)
    indicator_id = Column(Integer, ForeignKey("economic_indicators.id"), nullable=False)
    
    # Check details
    check_type = Column(String(50), nullable=False)  # completeness, accuracy, consistency, timeliness
    check_name = Column(String(100), nullable=False)
    check_timestamp = Column(DateTime(timezone=True), server_default=func.now())
    
    # Results
    passed = Column(Boolean, nullable=False)
    score = Column(Float)  # 0.0 to 1.0
    threshold = Column(Float)
    
    # Details
    description = Column(Text)
    failure_reason = Column(Text)
    affected_records = Column(Integer, default=0)
    
    # Date range checked
    date_from = Column(DateTime(timezone=True))
    date_to = Column(DateTime(timezone=True))
    
    # Metadata
    check_config = Column(JSON)
    result_details = Column(JSON)
    
    def __repr__(self):
        return f"<DataQualityCheck(indicator_id={self.indicator_id}, check_type='{self.check_type}', passed={self.passed})>"


class DataIngestionLog(Base):
    """Log of data ingestion operations"""
    __tablename__ = "data_ingestion_logs"
    
    id = Column(Integer, primary_key=True, index=True)
    batch_id = Column(String(100), unique=True, index=True, nullable=False)
    
    # Ingestion details
    source = Column(String(100), nullable=False)
    start_time = Column(DateTime(timezone=True), nullable=False)
    end_time = Column(DateTime(timezone=True))
    status = Column(String(20), nullable=False)  # running, completed, failed, cancelled
    
    # Statistics
    records_processed = Column(Integer, default=0)
    records_inserted = Column(Integer, default=0)
    records_updated = Column(Integer, default=0)
    records_skipped = Column(Integer, default=0)
    records_failed = Column(Integer, default=0)
    
    # Error handling
    error_message = Column(Text)
    error_details = Column(JSON)
    
    # Performance metrics
    processing_time_seconds = Column(Float)
    throughput_records_per_second = Column(Float)
    
    # Configuration
    ingestion_config = Column(JSON)
    
    def __repr__(self):
        return f"<DataIngestionLog(batch_id='{self.batch_id}', status='{self.status}', records_processed={self.records_processed})>"


class EconomicEvent(Base):
    """Significant economic events that might impact forecasts"""
    __tablename__ = "economic_events"
    
    id = Column(Integer, primary_key=True, index=True)
    
    # Event details
    name = Column(String(200), nullable=False)
    description = Column(Text)
    event_date = Column(DateTime(timezone=True), nullable=False, index=True)
    event_type = Column(String(50))  # policy_announcement, rate_change, crisis, etc.
    
    # Impact assessment
    significance_level = Column(String(20))  # low, medium, high, critical
    affected_indicators = Column(JSON)  # List of indicator codes
    
    # Source and metadata
    source = Column(String(100))
    source_url = Column(String(500))
    created_at = Column(DateTime(timezone=True), server_default=func.now())
    
    # Tags for categorization
    tags = Column(JSON)  # Flexible tagging system
    
    def __repr__(self):
        return f"<EconomicEvent(name='{self.name}', date='{self.event_date}', significance='{self.significance_level}')>"
